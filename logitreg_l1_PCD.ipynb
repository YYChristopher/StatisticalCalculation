{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression_L1_PCD:\n",
    "    \n",
    "    class Model:\n",
    "        \"\"\"\n",
    "        desc:训练出的模型\n",
    "        \"\"\"\n",
    "        def __init__(self,theta):\n",
    "            \"\"\"\n",
    "            desc:根据传入的 θ 构建模型 \n",
    "            \"\"\"\n",
    "            self.theta = theta\n",
    "        def predict(self,x_test):\n",
    "            \"\"\"\n",
    "            desc:根据传入的特征,利用模型预测数据\n",
    "            \"\"\"\n",
    "            t = np.dot(x_test, self.theta)\n",
    "            # 得出类别为 1 的概率\n",
    "            result = LogisticRegression_L1_PCD.sigmoid(t)\n",
    "            # 将所有数据取整  p > 0.5 return: 1 , p <= 0.5 return: 0\n",
    "            return np.round(result)\n",
    "    \n",
    "    def __init__(self,alpha,theta,valve,lamb,L,rand,batch_n=-1,max_iter=10**3):\n",
    "        \"\"\"\n",
    "        :param: alpha: 学习率,也称梯度下降中每一步的步长\n",
    "        :param: theta: 初始化的 θ 向量\n",
    "        :param: valve: 阀值,训练过程中,如梯度值的绝对值小于阀值就会跳出训练\n",
    "        :param: lamb: 正则化超参数（注意带默认值的参数要放在不带默认值参数的后面）\n",
    "        :param: rand: 坐标下降的过程中是否采用随机选择坐标下降。若为False则为循环坐标下降\n",
    "        :param: batch_n: 取一个整数表示微梯度下降中采用的样本数量,-1表示每次迭代采用全部数据\n",
    "        :param: max_iter: 最大的迭代次数,超过时自动跳出训练\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.theta = theta\n",
    "        self.valve = valve\n",
    "        self.lamb = lamb\n",
    "        self.L = L\n",
    "        self.rand = rand\n",
    "        self.batch_n = batch_n\n",
    "        self.max_iter = max_iter\n",
    "        \n",
    "    \n",
    "    def fit(self,x_data,y_data,coor):\n",
    "        \"\"\"\n",
    "        :param x_data: 特征值\n",
    "        :param y_data: 标签值\n",
    "        :param coor: 初始的迭代坐标轴编号。取值为(0,self.theta.shape[0]-1)范围内任一整数（前后均包含）\n",
    "        \"\"\"\n",
    "        iter_cnt = 0  #初始化迭代次数为0\n",
    "        data_len = x_data.shape[0]  #样本量n\n",
    "        # 验证样参数是否满足要求,并使其满足要求\n",
    "        self.batch_n = data_len if self.batch_n <= 0 or self.batch_n > data_len else self.batch_n\n",
    "        # 开始迭代\n",
    "        while self.__coordinate_func(x_data,y_data,coor) and iter_cnt < self.max_iter:\n",
    "            if self.rand == True:\n",
    "                coor = random.randint(0,self.theta.shape[0]-1)\n",
    "            else:\n",
    "                if coor < self.theta.shape[0]-1:\n",
    "                    coor += 1\n",
    "                else:\n",
    "                    coor = 0\n",
    "           \n",
    "            iter_cnt += 1  #可以用loss_list记录下损失\n",
    "        return self.Model(self.theta)\n",
    "    \n",
    "    def __coordinate_func(self,x_data,y_data,coor):\n",
    "        \"\"\"\n",
    "        :param x_data: 特征值\n",
    "        :param y_data: 标签值\n",
    "        \"\"\"\n",
    "        data_len = x_data.shape[0]  #样本量n\n",
    "        fetature_len = self.theta.shape[0]  #特征数p\n",
    "\n",
    "        j_ = 0\n",
    "        # 遍历样本数据\n",
    "        for i in range(0,data_len,round(data_len/self.batch_n)):  #按照批量进行计算\n",
    "            # 计算θx_1 + θx_2 + ... + θx_n    也就是公式中的(θ^TX)\n",
    "            t1 = np.dot(x_data[i], self.theta)\n",
    "            # 计算预测值 h_θ(x_i)\n",
    "            h_theta = LogisticRegression_L1_PCD.sigmoid(t1)\n",
    "            # 结果累加起来 (h_θ(x_i) - y_i)x_ij\n",
    "            j_ += (h_theta-y_data[i])*x_data[i][coor]\n",
    "        # 除以处理的样本数量,也就是取均值\n",
    "        j_ /= self.batch_n\n",
    "        para_change = j_/self.L\n",
    "        z = self.theta[coor] - para_change\n",
    "\n",
    "        if self.lamb/self.L < z:\n",
    "            self.theta[coor] = z - self.lamb/self.L\n",
    "        elif z < -self.lamb/self.L:\n",
    "            self.theta[coor] = z + self.lamb/self.L\n",
    "        else:\n",
    "            self.theta[coor] = 0\n",
    "        # 判断参数theta的改变是否大于阈值\n",
    "        return np.abs(para_change) >= self.valve\n",
    "    \n",
    "    @staticmethod\n",
    "    def sigmoid(x):\n",
    "        t = 1 + np.exp(-x)\n",
    "        result = np.divide(1,t)\n",
    "        return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用鸢尾花数据集进行验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris_data = np.column_stack(load_iris(return_X_y=True))\n",
    "# 这里我们实现的只是二分类算法,左右只需要类别0和类别1两种即可\n",
    "iris_data = iris_data[iris_data[:,-1]<2]\n",
    "# 将数据打乱\n",
    "np.random.shuffle(iris_data)\n",
    "# 将数据分成两份\n",
    "train_x,test_x,train_y,test_y = train_test_split(iris_data[:,:-1],iris_data[:,-1],test_size=0.3,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ini_theta = np.array([1]*train_x.shape[1],dtype=float)\n",
    "coor = random.randint(0,ini_theta.shape[0]-1)\n",
    "l = LogisticRegression_L1_PCD(alpha=0.01,theta=ini_theta,valve=0.00001,lamb=0.01,L=1.5,rand=False,batch_n=-1,max_iter=1000)  #坐标梯度下降，batch_n应当取全部样本\n",
    "m = l.fit(train_x,train_y,coor)\n",
    "pred_y = m.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测准确率为:1.0000\n",
      "预测查准率为:1.0000\n",
      "预测召回率为:1.0000\n",
      "预测f1-score为:1.0000\n",
      "模型beta参数估计为 [-1.61742813 -0.46257661  3.5239059   0.56606718]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "acc = accuracy_score(test_y,pred_y)\n",
    "rec = recall_score(test_y,pred_y)\n",
    "pre = precision_score(test_y,pred_y)\n",
    "f1 = f1_score(test_y,pred_y)\n",
    "\n",
    "print('预测准确率为:{:.4f}'.format(acc))\n",
    "print('预测查准率为:{:.4f}'.format(pre))\n",
    "print('预测召回率为:{:.4f}'.format(rec))\n",
    "print('预测f1-score为:{:.4f}'.format(f1))\n",
    "print('模型beta参数估计为',m.theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测准确率为:1.0000\n",
      "预测查准率为:1.0000\n",
      "预测召回率为:1.0000\n",
      "预测f1-score为:1.0000\n",
      "采用sklearn模型系数为 [[ 0.         -2.26425929  2.56759734  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_l1 = LogisticRegression(penalty=\"l1\", solver=\"liblinear\", max_iter=1000)\n",
    "lr_l1.fit(train_x,train_y)\n",
    "pred_y_lr = lr_l1.predict(test_x)\n",
    "\n",
    "acc = accuracy_score(test_y,pred_y_lr)\n",
    "rec = recall_score(test_y,pred_y_lr)\n",
    "pre = precision_score(test_y,pred_y_lr)\n",
    "f1 = f1_score(test_y,pred_y_lr)\n",
    "\n",
    "print('预测准确率为:{:.4f}'.format(acc))\n",
    "print('预测查准率为:{:.4f}'.format(pre))\n",
    "print('预测召回率为:{:.4f}'.format(rec))\n",
    "print('预测f1-score为:{:.4f}'.format(f1))\n",
    "print('采用sklearn模型系数为',lr_l1.coef_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 用第五次作业数据进行验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# 训练数据\n",
    "train_x = train_data.iloc[:,1:].values \n",
    "train_y = np.array(train_data.iloc[:,0])\n",
    "# 测试数据\n",
    "test_x = test_data.iloc[:,1:].values\n",
    "test_y = np.array(test_data.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ini_theta = np.array([1]*train_x.shape[1],dtype=float)\n",
    "l = LogisticRegression_L1_PCD(alpha=0.01,theta=ini_theta,valve=0.00001,lamb=0.01,L=1,rand=False,batch_n=-1,max_iter=1000)  #坐标梯度下降，batch_n应当取全部样本\n",
    "coor = random.randint(0,ini_theta.shape[0]-1)\n",
    "m = l.fit(train_x,train_y,coor)\n",
    "pred_y = m.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测准确率为:0.7250\n",
      "预测查准率为:0.7000\n",
      "预测召回率为:0.7368\n",
      "预测f1-score为:0.7179\n",
      "模型系数为 [ 1.0821291   1.29101239  0.31384235 -0.88241532 -1.86872265]\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(test_y,pred_y)\n",
    "rec = recall_score(test_y,pred_y)\n",
    "pre = precision_score(test_y,pred_y)\n",
    "f1 = f1_score(test_y,pred_y)\n",
    "\n",
    "print('预测准确率为:{:.4f}'.format(acc))\n",
    "print('预测查准率为:{:.4f}'.format(pre))\n",
    "print('预测召回率为:{:.4f}'.format(rec))\n",
    "print('预测f1-score为:{:.4f}'.format(f1))\n",
    "print('模型系数为',m.theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测准确率为:0.7250\n",
      "预测查准率为:0.6667\n",
      "预测召回率为:0.8421\n",
      "预测f1-score为:0.7442\n",
      "采用sklearn模型系数为 [[ 1.20277134  1.42406339  0.40366944 -1.10677098 -1.98585048]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_l1 = LogisticRegression(penalty=\"l1\", solver=\"liblinear\", max_iter=1000)\n",
    "lr_l1.fit(train_x,train_y)\n",
    "pred_y_lr = lr_l1.predict(test_x)\n",
    "\n",
    "acc = accuracy_score(test_y,pred_y_lr)\n",
    "rec = recall_score(test_y,pred_y_lr)\n",
    "pre = precision_score(test_y,pred_y_lr)\n",
    "f1 = f1_score(test_y,pred_y_lr)\n",
    "\n",
    "print('预测准确率为:{:.4f}'.format(acc))\n",
    "print('预测查准率为:{:.4f}'.format(pre))\n",
    "print('预测召回率为:{:.4f}'.format(rec))\n",
    "print('预测f1-score为:{:.4f}'.format(f1))\n",
    "print('采用sklearn模型系数为',lr_l1.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16f5b46f222e2a3e8d4adbf7141cae37b71ed37616e60735fa5d1164a1bc3ada"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
